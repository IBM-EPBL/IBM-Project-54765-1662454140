# -*- coding: utf-8 -*-
"""model building

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M8swRzEuerTlr_g4szlkqnjZUyc-YkOM
"""

import keras
from keras.preprocessing.image import ImageDataGenerator
#Define the parameters/arguments for ImageDataGenerator class
train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)

test_datagen=ImageDataGenerator(rescale=1./255)
#Applying ImageDataGenerator functionality to trainset
x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/train_set',target_size=(128,128),batch_size=32,class_mode='binary')
Found 436 images belonging to 2 classes.
#Applying ImageDataGenerator functionality to testset
x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Dataset/test_set',target_size=(128,128),batch_size=32,class_mode='binary')
Found 121 images belonging to 2 classes.
#import model building libraries

#To define Linear initialisation import Sequential
from keras.models import Sequential
#To add layers import Dense
from keras.layers import Dense
#To create Convolution kernel import Convolution2D
from keras.layers import Convolution2D
#import Maxpooling layer
from keras.layers import MaxPooling2D
#import flatten layer
from keras.layers import Flatten
import warnings
warnings.filterwarnings('ignore')
#initializing the model
model=Sequential()
#add convolutional layer
model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))
#add maxpooling layer
model.add(MaxPooling2D(pool_size=(2,2)))
#add flatten layer 
model.add(Flatten())
#add hidden layer
model.add(Dense(150,activation='relu'))
#add output layer
model.add(Dense(1,activation='sigmoid'))
#configure the learning process
model.compile(loss='binary_crossentropy',optimizer="adam",metrics=["accuracy"])
#Training the model
model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)
Epoch 1/10
14/14 [==============================] - 153s 11s/step - loss: 0.6812 - accuracy: 0.6399 - val_loss: 0.6765 - val_accuracy: 0.5950
Epoch 2/10
14/14 [==============================] - 26s 2s/step - loss: 0.6577 - accuracy: 0.6445 - val_loss: 0.6765 - val_accuracy: 0.5950
Epoch 3/10
14/14 [==============================] - 25s 2s/step - loss: 0.6532 - accuracy: 0.6445 - val_loss: 0.6820 - val_accuracy: 0.5950
Epoch 4/10
14/14 [==============================] - 26s 2s/step - loss: 0.6512 - accuracy: 0.6445 - val_loss: 0.6794 - val_accuracy: 0.5950
Epoch 5/10
14/14 [==============================] - 25s 2s/step - loss: 0.6510 - accuracy: 0.6445 - val_loss: 0.6793 - val_accuracy: 0.5950
Epoch 6/10
14/14 [==============================] - 25s 2s/step - loss: 0.6509 - accuracy: 0.6445 - val_loss: 0.6806 - val_accuracy: 0.5950
Epoch 7/10
14/14 [==============================] - 26s 2s/step - loss: 0.6509 - accuracy: 0.6445 - val_loss: 0.6807 - val_accuracy: 0.5950
Epoch 8/10
14/14 [==============================] - 25s 2s/step - loss: 0.6513 - accuracy: 0.6445 - val_loss: 0.6815 - val_accuracy: 0.5950
Epoch 9/10
14/14 [==============================] - 25s 2s/step - loss: 0.6511 - accuracy: 0.6445 - val_loss: 0.6797 - val_accuracy: 0.5950
Epoch 10/10
14/14 [==============================] - 26s 2s/step - loss: 0.6514 - accuracy: 0.6445 - val_loss: 0.6809 - val_accuracy: 0.5950
model.save("forest1.h5")
#import load_model from keras.model
from keras.models import load_model
#import image class from keras
from tensorflow.keras.preprocessing import image
#import numpy
import numpy as np
#import cv2
import cv2
#load the saved model
model = load_model("forest1.h5")
img=image.load_img('/content/drive/MyDrive/Dataset/Dataset/test_set/with fire/180802_CarrFire_010_large_700x467.jpg')
x=image.img_to_array(img)
res = cv2.resize(x, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)
#expand the image shape
x=np.expand_dims(res,axis=0)
pred=model.predict(x)
1/1 [==============================] - 0s 243ms/step
pred
array([[0.35252538]], dtype=float32)